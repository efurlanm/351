# Neurocomputing (CAP 351)

*Last edited: 2024-02-27*

My personal notes from the course and assignments.

The CAP 351 course is part of the [Applied Artificial Intelligence Track](http://www.inpe.br/posgraduacao/cap/catalogo-disciplinas.php).


## Directories

- [manuscript](manuscript) - Academic manuscript of the project developed in the course (in Portuguese).
- [kaggle_fork](kaggle_fork) - Fork from Kaggle repositories available at https://www.kaggle.com/phelpsmemo/code
- [plotmaps](plotmaps) - Examples of rectangular and hexagonal maps, mainly based on https://github.com/mstaczek/miowad


## Some topics and links to interesting pages

- Neural network
- Historic
- Concepts and definitions
- Learning paradigms and rules
- [Perceptrons](https://en.wikipedia.org/wiki/Perceptron)
- [Multilayer Perceptrons (MLP)](https://en.wikipedia.org/wiki/Multilayer_perceptron)
- [Backpropagation](https://en.wikipedia.org/wiki/Backpropagation) algorithm and its variations
- [Topology](https://www.researchgate.net/figure/Neural-network-model-topology-and-layer-configuration-represented-by-a-p-dimensional_fig1_312082939) configuration techniques
- [Regularizations](https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques/)
- [Autoencoders](https://www.analyticsvidhya.com/blog/2021/10/an-introduction-to-autoencoders-for-beginners/)
- Competitive neural networks: SOM, GNG, PCA
- [Hopfield network](https://www.geeksforgeeks.org/hopfield-neural-network/)
- [Boltzmann machines](https://www.geeksforgeeks.org/types-of-boltzmann-machines/) and constrained Boltzmann machines
- [Introduction to deep architectures: DNN, CNN, RNN](https://www.geeksforgeeks.org/difference-between-ann-cnn-and-rnn/)
- [Software](https://en.wikipedia.org/wiki/Neural_network_software) and applications


## Hands-on works

- [`project1-mlp.ipynb`](https://github.com/efurlanm/351/blob/main/projecto1-mlp.ipynb) - Multilayer perceptron (MLP) is a fully connected class of feedforward artificial neural network (ANN). [[Source]](https://en.wikipedia.org/wiki/Multilayer_perceptron)
- [`project2-som.ipynb`](https://github.com/efurlanm/351/blob/main/project2-som.ipynb) - A self-organizing map or self-organizing feature map is an unsupervised machine learning technique used to produce a low-dimensional representation of a higher dimensional data set while preserving the topological structure of the data. [[Source]](https://en.wikipedia.org/wiki/Self-organizing_map)
- [`project3-vae.ipynb`](https://github.com/efurlanm/351/blob/main/project3-vae.ipynb) - In machine learning, a variational autoencoder, is an artificial neural network architecture introduced by Diederik P. Kingma and Max Welling, belonging to the families of probabilistic graphical models and variational Bayesian methods. [[Source]](https://en.wikipedia.org/wiki/Variational_autoencoder)
- [`project4-cnn.ipynb`](https://github.com/efurlanm/351/blob/main/project4-cnn.ipynb) - A Convolutional Neural Network (CNN, or ConvNet) is a class of artificial neural network (ANN), most commonly applied to analyze visual imagery. CNNs are also known as Shift Invariant or Space Invariant Artificial Neural Networks (SIANN), based on the shared-weight architecture of the convolution kernels or filters that slide along input features and provide translation-equivariant responses known as feature maps. [[Source]](https://en.wikipedia.org/wiki/Convolutional_neural_network)
- [`project5-rnn.ipynb`](https://github.com/efurlanm/351/blob/main/project5-rnn.ipynb) - A Recurrent Neural Network (RNN) is a class of artificial neural networks where connections between nodes can create a cycle, allowing output from some nodes to affect subsequent input to the same nodes. [[Source]](https://en.wikipedia.org/wiki/Recurrent_neural_network)


## Some selected topics from CAP 421 (only for reference)

- Definition and applications of Deep Learning
- Basics of Digital Image Processing
- Convolution: Padding, Filter Dimension, Stride, Dilation
- Review of Multi-Layer Perceptron Neural Networks with Backpropagation Algorithm
- Loss Functions and Optimizers
- Convolutional Neural Networks (CNNs)
- Convolutional, Pooling, and Fully Connected Layers
- Activation Functions
- Batch Normalization
- Dropout
- Transfer of Learning
- Data Augmentation
- Hyperparameter Tuning
- Examples of CNN Architectures
- Recurrent Neural Networks (RNNs)
- Generative Models
- Generative Adversarial Networks (GANs)
- Deep Reinforcement Learning


## Some selected topics from CAP 354 (only for reference)

- [Fuzzy logic](https://en.wikipedia.org/wiki/Fuzzy_logic)
- [Non-classical logic](https://en.wikipedia.org/wiki/Non-classical_logic)
- [Perceptron neural networks](https://towardsdatascience.com/what-is-a-perceptron-basics-of-neural-networks-c4cfea20c590)
- [SOM (Self-Organizing Map)](https://en.wikipedia.org/wiki/Self-organizing_map)
- [Neural gas](https://en.wikipedia.org/wiki/Neural_gas)
- [Case-based reasoning](https://en.wikipedia.org/wiki/Case-based_reasoning)
- [Genetic algorithm](https://en.wikipedia.org/wiki/Genetic_algorithm)
- [Intelligent agent](https://en.wikipedia.org/wiki/Intelligent_agent)
- [Deep learning](https://en.wikipedia.org/wiki/Deep_learning)
- [Knowledge representation and reasoning](https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning)
- [Natural language processing](https://en.wikipedia.org/wiki/Natural_language_processing)


## Python distribution

- The [Anaconda Python distribution](https://www.anaconda.com/products/distribution) was used to run the Notebooks in this repository

- Anaconda's default Conda package manager was used to install additional required packages


## Links of interest

- [The Evolution and Core Concepts of Deep Learning & Neural Networks](https://www.analyticsvidhya.com/blog/2016/08/evolution-core-concepts-deep-learning-neural-networks/)

- [Josh Starmer](https://www.youtube.com/playlist?list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1) - series of videos about Neural Networks

- [NPTEL](https://www.youtube.com/channel/UCYa1WtI-vb_bx-anHdmpNfA/search?query=neural) - an Indian government project, provides a series of videos on Neural Networks

- [Deep Learning Book](https://www.deeplearningbook.com.br/) (in Portuguese) - online book showing Perceptron and Multilayer Perceptron models, Backpropagation, Convolutional Neural Networks, Recurrent Neural Networks, Autoencoders, Generative Adversarial Network, Deep Reinforcement Learning, and other subjects

- [Deep Learning Wizard](https://www.deeplearningwizard.com) - tutorials, courses, and over 6000 deep learning wizards 

- [Artificial Neural Networks](https://en.wikibooks.org/wiki/Artificial_Neural_Networks) - Wikibooks containing ANN models, teaching and learning, and applications


## Videos of interest

- [Machine Learning — Andrew Ng, Stanford University](https://www.youtube.com/playlist?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN) (Playlist) - provides a broad introduction to machine learning, datamining, and statistical pattern recognition
  
  - [Coursera description](https://www.coursera.org/learn/machine-learning)

- [MIT course 6.034 Artificial Intelligence](https://www.youtube.com/playlist?list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi) (Playlist) - introduces the basic knowledge representation, problem solving, and learning methods of artificial intelligence
  
  - [Instructor Insights](https://ocw.mit.edu/courses/6-034-artificial-intelligence-fall-2010/pages/instructor-insights/)

- [Heroes of Deep Learning: Andrew Ng interviews Yann LeCun](https://youtu.be/Svb1c6AkRzE) (with Subtitles/CC) - Yann André LeCun is a French computer scientist working primarily in the fields of machine learning, computer vision, mobile robotics, and computational neuroscience. He is the Silver Professor of the Courant Institute of Mathematical Sciences at New York University, and Vice President, Chief AI Scientist at Meta. [[Source]](https://en.wikipedia.org/wiki/Yann_LeCun)

- [Heroes of Deep Learning: Andrew Ng interviews Ian Goodfellow](https://youtu.be/pWAc9B2zJS4) (with Subtitles/CC) - Ian J. Goodfellow is a computer scientist, engineer, and executive, most noted for his work on artificial neural networks and deep learning. He was previously employed as a research scientist at Google Brain and director of machine learning at Apple and has made several important contributions to the field of deep learning including the invention of the generative adversarial network (GAN). [[Source]](https://en.wikipedia.org/wiki/Ian_Goodfellow)

- [Heroes of Deep Learning: Andrew Ng interviews Geoffrey Hinton](https://youtu.be/-eyhCTvrEtE) (with Subtitles/CC) - Geoffrey Everest Hinton is a British-Canadian cognitive psychologist and computer scientist, most noted for his work on artificial neural networks. Since 2013, he has divided his time working for Google (Google Brain) and the University of Toronto. [[Source]](https://en.wikipedia.org/wiki/Geoffrey_Hinton)

- [Heroes of Deep Learning: Andrew Ng interviews Yoshua Bengio](https://youtu.be/pnTLZQhFpaE) (with Subtitles/CC) - Yoshua Bengio is a Canadian computer scientist, most noted for his work on artificial neural networks and deep learning. He is a professor at the Department of Computer Science and Operations Research at the Université de Montréal and scientific director of the Montreal Institute for Learning Algorithms (MILA). [[Source]](https://en.wikipedia.org/wiki/Yoshua_Bengio)


## References

- GOODFELLOW, I.; BENGIO, Y.; COURVILLE, A. [Deep learning](https://www.google.com.br/books/edition/Deep_Learning/Np9SDQAAQBAJ). Cambridge, Massachusetts: The MIT Press, 2016. ISBN: 9780262035613. Available at: https://www.deeplearningbook.org
- BRAGA, A. D. P., CARVALHO, A. C. P. D. L. F., & LUDERMIR, T. B. [Redes neurais artificiais](https://www.skoob.com.br/redes-neurais-artificiais-222201ed300416.html): teoria e aplicações (in Portuguese). Rio de Janeiro: LTC, 2000. ISBN: 8521612184
- HAYKIN, S. [Neural networks: a comprehensive foundation](https://www.google.com.br/books/edition/Neural_Networks/bX4pAQAAMAAJ). 2nd ed ed. Upper Saddle River, N.J: Prentice Hall, 1999. ISBN: 9780132733502
- HAYKIN, S. [Neural networks and learning machines](https://www.google.com.br/books/edition/_/faouAAAAQBAJ), 3/E. Pearson Education India, 2009. ISBN: 9780133002553
- RUMELHART, D. E.; MCCLELLAND, J. L. [Parallel distributed processing: explorations in the microstructure of cognition](https://mitpress.mit.edu/books/parallel-distributed-processing-volume-1). Cambridge, Mass: MIT Press, 1986. ISBN: 9780262181204
- LECUN, Y.; BENGIO, Y.; HINTON, G. [Deep learning](https://www.nature.com/articles/nature14539). Nature, v. 521, n. 7553, p. 436–444, 28 maio 2015. https://doi.org/10.1038/nature14539
- RR Rosa; JDS da Silva. [Topics of computational intelligence applied to space technologies](http://mtc-m16c.sid.inpe.br/col/urlib.net/www/2011/03.29.20.55/doc/mirrorget.cgi?languagebutton=en&metadatarepository=sid.inpe.br/mtc-m18@80/2008/12.19.13.18.16&index=0&serveraddress=mtc-m16c.sid.inpe.br%20804&choice=full&lastupdate=2021:04.14.18.47.25%20sid.inpe.br/mtc-m18@80/2008/03.17.15.17%20marciana%20%7BD%202008%7D&continue=no&keywords=&accent=yes&case=yes&imageflag=0&mirrorgetflag=1) (in Portuguese). 2008. ISBN: 978-85-17-00037-9
- RUSSELL, S J; NORVIG P. [Artificial Intelligence](http://aima.cs.berkeley.edu/): A Modern Approach. 2020. ISBN: 0134610997
